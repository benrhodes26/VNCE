{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using variational EM-type procedure to maximize J1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\nabla_{w}J_1(w)$ - general case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the normalised-MOG notebook, we considered an EM-type algorithm where we update a variational distribution to be equal to the posterior over latent variables given the data and current value of $\\theta$. Now let's pretend (as is generally true) that the posterior is intracable. In this setting, we parameterise our variational distribution with parameters $w$, and optimise them in conjuction with theta (using co-oordinate ascent). \n",
    "\n",
    "To optimise our objective function w.r.t to $\\textbf{w}$, we need to find the gradient of:\n",
    "\n",
    "\\begin{align}\n",
    "J_1^k(\\textbf{w}) = \\color{red}{ - \\mathbb{E}_{x} \\mathbb{E}_{z \\sim q(z \\ | \\ u; \\textbf{w})} \\left[ \\log(1 + \\frac{\\nu}{r(x, z; \\textbf{w})}) \\right]} - \\color{blue}{ \\nu \\mathbb{E}_{y}  \\left[ \\log(1 + \\frac{1}{\\nu} \\mathbb{E}_{z \\sim q(z \\ | \\ u; \\textbf{w})}[r(y, z; \\textbf{w})] ) \\right]}\n",
    "\\end{align}\n",
    "\n",
    "where \n",
    "\n",
    "$$ r(u,z, \\textbf{w}) = \\frac{\\phi(u, z; \\theta_k)}{q_k(z \\ | \\ u; \\textbf{w}) p_y(u)}$$\n",
    "\n",
    "Note that this is a *stochastic* optimisation problem, since we are differentiating w.r.t to parameters of q, but there is an expectation over q. This complicates the situation.\n",
    "\n",
    "For simple q distributions, we might be able to analytically evaluate these expectations, and then take derivatives. For more complex distributions, we will need to use something else: perhaps a pathwise derivative estimator (http://blog.shakirm.com/2015/10/machine-learning-trick-of-the-day-4-reparameterisation-tricks/) or score function estimator (http://blog.shakirm.com/2015/11/machine-learning-trick-of-the-day-5-log-derivative-trick/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\nabla_{w}J_1(w)$ - Mixture Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our gaussian mixture model, the binary latent variable must have a bernouilli distribution, and so we can analytically evaluate expectations with respect to it. \n",
    "\n",
    "We will consider a bernoulli distribution where the probability of $z = 0$ is given by a quadratic sigmoid. This functional form matches that of the true posterior, and so by optimising the parameters $w$, we hope to recover the true posterior.\n",
    "\n",
    "$$ q(z=0 \\ | \\ u; \\textbf{w}) = \\sigma(\\textbf{w}^T \\tilde{\\textbf{u}}) = \\sigma(w_0 + w_1u + w_2u^2) $$\n",
    "\n",
    "where $\\sigma$ is the sigmoid function,  $\\textbf{w}$ are the variational parameters and $\\tilde{\\textbf{u}} := (1, u, u^2)^T$. We recover the true posterior by setting:\n",
    "$$ \\textbf{w} = \\left[-\\log(\\theta), \\ 0, \\ \\frac{1}{2}(1 - \\theta^{-2}) \\right] $$\n",
    "We will then alternate optimisation of $\\theta$ and $\\textbf{w}$ (i.e apply a form of coordinate ascent)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate $\\nabla_{\\textbf{w}} J_1^k(\\textbf{w})$, we first analytically evaluate the expectations. Doing this, we see that the blue term will no longer depend on q (since q was only introduced in the blue term for importance sampling, which we now undo). Hence, we only have to evaluate:\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_{\\textbf{w}} J_1^k(\\textbf{w}) & = \\color{red}{\\nabla_{\\textbf{w}} \\left[ -\\mathbb{E}_x \\sum_{i=1}^2 q(i \\ | \\ x; \\textbf{w}) \\log \\left( 1 + \\nu\\frac{ q(i \\ | \\ x; \\textbf{w}) p_y(x)}{\\phi(x, i, \\theta_k)} \\right) \\right]}\n",
    "\\end{align}\n",
    "\n",
    "The gradient of a term inside the summation has the form:\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_{\\textbf{w}} \\left[ q_i(\\textbf{w}) \\log( 1 + a_iq_i(\\textbf{w})) \\right] = \\left( \\log( 1 + a_iq_i(\\textbf{w})) + \\frac{a_i q_i(\\textbf{w})}{1 + a_i q_i(\\textbf{w})} \\right) \\nabla_{\\textbf{w}} q_i(\\textbf{w})\n",
    "\\end{align}\n",
    "\n",
    "Where we have simplified notation by setting: $q_i(\\textbf{w}) = q(i \\ | \\ x; \\textbf{w})$ and $ a_i = \\nu \\frac{p_y(x)}{\\phi(x, i, \\theta_k)}$.\n",
    "\n",
    "Observe that \n",
    "\n",
    "$$\\nabla_{\\textbf{w}} q_1(\\textbf{w}) =  \\nabla_{\\textbf{w}} \\left[ 1 - q_0(\\textbf{w}) \\right] = - \\nabla_{\\textbf{w}} q_0(\\textbf{w}) $$\n",
    "\n",
    "and so our original gradient becomes:\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_{\\textbf{w}} J_1^k(\\textbf{w}) \n",
    "    & = \\color{red}{ \\mathbb{E}_x  \\left( \\log \\left( \\frac{ 1 + a_0q_0(\\textbf{w})}{1 + a_1q_1(\\textbf{w})} \\right) \n",
    "        +\\frac{a_0 q_0(\\textbf{w})}{1 + a_0 q_0(\\textbf{w})} \n",
    "        -\\frac{a_1 q_1(\\textbf{w})}{1 + a_1 q_1(\\textbf{w})}  \\right) \n",
    "          \\nabla_{\\textbf{w}} q_1(\\textbf{w})}\n",
    "\\end{align}\n",
    "\n",
    "where, using the definition of $q$, we have:\n",
    "\n",
    "\\begin{align} \n",
    "\\nabla_{\\textbf{w}} q_0(\\textbf{w}) & = \\nabla_{\\textbf{w}} q(z=0 \\ | \\ x; \\textbf{w}) \\\\\n",
    "& = \\nabla_{\\textbf{w}} \\left[ \\sigma(\\textbf{w}^T \\tilde{\\textbf{x}}) \\right] \\\\\n",
    "& = \\sigma(\\textbf{w}^T \\tilde{\\textbf{x}}) (1 - \\sigma(\\textbf{w}^T \\tilde{\\textbf{x}})) \\tilde{\\textbf{x}}\n",
    "\\end{align}\n",
    "\n",
    "Note that the above derivation actually applies to **any binary latent variable model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "# my code\n",
    "from distribution import PolynomialSigmoidBernoulli, GaussianNoise\n",
    "from gaussian_mixture_analytic_expectations import *\n",
    "from vnce_optimisers import VNCEOptimiserWithAnalyticExpectations\n",
    "from latent_variable_model import MixtureOfTwoGaussians\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rc\n",
    "from numpy import random as rnd\n",
    "\n",
    "%matplotlib inline\n",
    "rc('lines', linewidth=1)\n",
    "rc('font', size=18)\n",
    "rc('legend', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "rng = rnd.RandomState(1083463236)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixing proportions: 0.5 and 0.5\n",
    "# mean0 = mean1 = 0\n",
    "sigma1 = 1\n",
    "sigma0 = 4  # (parameter of interest)\n",
    "\n",
    "n = 10000 # number of data points\n",
    "nz = 1  # number of latent samples per datapoint\n",
    "nu = 1 # nu is the ratio of noise to data samples in NCE\n",
    "\n",
    "theta0 = 0.5  # initial theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_data_dist = MixtureOfTwoGaussians(theta=np.log(sigma0), sigma1=sigma1)\n",
    "X = true_data_dist.sample(n) # generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = GaussianNoise(mean=0, cov = sigma0**2)\n",
    "Y = noise.sample(n*nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MixtureOfTwoGaussians(theta0, sigma1=sigma1)\n",
    "var_dist = PolynomialSigmoidBernoulli(alpha=np.array([0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E(r(x, z))\n",
    "E1 = E_r\n",
    "# E(log(psi_1(x, z)))\n",
    "E2 = E_log_psi_1\n",
    "# E((psi_1(x, z) - 1) / psi_1(x, z))\n",
    "E3 = E_psi_1_ratio_times_grad_log_theta\n",
    "# E(grad_theta(log(phi(u,z)) r(u, z))\n",
    "E4 = E_r_times_grad_log_theta\n",
    "# gradient_alpha(E(log(psi_1(x, z)))\n",
    "E5 = grad_wrt_alpha_of_E_log_psi_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = VNCEOptimiserWithAnalyticExpectations(model, noise, Y, var_dist, E1, E2, E3, E4, E5, nu=nu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational EM-type optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "thetas_per_em, alphas_per_em, J1s, times = optimiser.fit(X, \n",
    "                                                         theta0=np.log(4), \n",
    "                                                         alpha0=np.array([0, 0, 0]), \n",
    "                                                         maxiter=1000, \n",
    "                                                         disp=False, \n",
    "                                                         stop_threshold=10**-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f93e01deb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = optimiser.plot_loss_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinate ascent visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.arange(0.01, 8, 0.1).reshape(-1, 1)\n",
    "n_theta = len(thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(u):\n",
    "    return np.log(model.marginalised_over_z(u)) - np.log(noise(u))\n",
    "\n",
    "J = np.zeros(n_theta)\n",
    "for k in range(n_theta):\n",
    "    model.theta = np.log(thetas[k])\n",
    "\n",
    "    a0 = 1 + nu*np.exp(-h(X))\n",
    "    a1 = 1 + (1/nu)*np.exp(h(Y))\n",
    "    \n",
    "    J[k] = -np.mean(np.log(a0)) - nu*np.mean(np.log(a1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_m_steps = len(thetas_per_em)  # includes initialisation\n",
    "num_e_steps = len(alpha_per_em)  # includes intialisation\n",
    "lower_bounds = [np.zeros(n_theta) for i in range(num_e_steps)]\n",
    "for i in range(num_e_steps):\n",
    "    var_dist.alpha = alpha_per_em[i]\n",
    "    for j in range(n_theta):\n",
    "        model.theta = np.log(thetas[j])\n",
    "        lower_bounds[i][j] = optimiser.compute_J1(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "rc('lines', linewidth=2)\n",
    "rc('font', size=12)\n",
    "rc('legend', fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this code does not currently produce the correct figure because we are updating thetas_per_em and alphas_per_em\n",
    "# during every iteration of scipy.minimize. If we switched to updating only at end of each E or M step, it would work.\n",
    "\"\"\"num_em_steps = num_e_steps + num_m_steps - 1  # minus 1 for double counting intialisation\n",
    "fig, axs = plt.subplots(num_em_steps, 1, figsize=(10, 18))\n",
    "axs = axs.ravel()\n",
    "for i in range(num_em_steps):\n",
    "    # plot NCE objective and its maximum\n",
    "    axs[i].plot(thetas, J, label=r'NCE objective $J(\\theta)$')\n",
    "    J_index = np.argmax(J)\n",
    "    axs[i].plot(thetas[J_index],J[J_index], marker='o', markersize=10, fillstyle='none', \n",
    "         markeredgewidth=1.5, c='b', linestyle='none', label=r'maximum of $J(\\theta)$')\n",
    "    \n",
    "    E_step_id = int(i/2)\n",
    "    M_step_id = int(np.ceil(i/2))\n",
    "    \n",
    "    # plot current lower bound J1\n",
    "    lb = lower_bounds[E_step_id]\n",
    "    axs[i].plot(thetas, lb, label=r'lower bound $J^1_{\\theta_{%d}}(\\theta)$' % int(i/2))\n",
    "   \n",
    "    # maximiser of lower bound\n",
    "    lb_index = np.argmax(lb)\n",
    "    axs[i].plot(thetas[lb_index], lb[lb_index], 'rs', markersize=10, fillstyle='none', \n",
    "             markeredgewidth=1.5, linestyle='none', label=r'maximum of $J^1_{\\theta_{%d}}(\\theta)$' % int(i/2))\n",
    "    \n",
    "    # current theta value\n",
    "    axs[i].plot(np.exp(thetas_per_em[M_step_id]) * np.array([1,1]),\n",
    "                plt.get(axs[i],'ylim'), 'g--', label=r'$\\theta_{}$'.format(int(np.ceil(i/2))))\n",
    "    # true param value\n",
    "    axs[i].plot(sigma0 * np.array([1,1]), plt.get(axs[i],'ylim'), 'k--', label='true parameter value')\n",
    "\n",
    "    axs[i].set_xlabel(r'${\\theta}$', fontsize=12)\n",
    "    axs[i].set_ylabel('objective', fontsize=12)\n",
    "    axs[i].legend(loc='lower right', numpoints=1, fontsize=12)\n",
    "    axs[i].grid()\n",
    "fig.tight_layout()\n",
    "fig.savefig('../../figs/variational-em.pdf')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
